## Forward Kernel 实现

naive.py 是一个朴素实现的 PyTorch kernel。

它由以下组件构成：

1. **build_tree**: 根据传入的 final state（最底层所有 token 的 Key Value Query State），构建出 htree 数据结构的所有上层节点。关于构建"代表"token 的压缩算法，我们目前只支持并选择 mean pooling，后续将支持 window_attention。在这个组件中，根据需要创建 L-1 个 tensor（每个非叶子层用一个 tensor 存储）。这可以看作是初始化步骤。

2. **compute_and_select**: 从参数传入整个分层结构与当前需要处理的层级索引，返回该层的候选节点和选中节点的信息。实现流程：
   - **确定候选节点范围**：
     - 顶层：考虑整层所有左边界 ≤ m 的节点。包含位置 m 的节点因其左边界 ≤ m，会被保留在候选集中
     - 非顶层：考虑上一层选中的节点的所有子节点，对于上一层选中的最右端父节点在该层中的儿子，丢弃左边界 > m 的节点。包含位置 m 的节点必然被保留
   - **计算注意力分数**：
     - 对所有候选节点按索引排序（等价于按左边界排序），依次赋予 RoPE 位置编码 0, 1, 2, ..., (num_candidates-1)
     - 对当前 Query Vector q 应用 RoPE 位置编码 num_candidates
     - 计算 q 关于所有候选节点的注意力分数
   - **选择 Top-K**（仅非最底层执行）：
     - 给包含位置 m 的最右侧节点加极大分数加成（如 +1e9），确保它一定被 Top-K 选中
     - 选择注意力分数最高的 min(512, num_candidates) 个节点用于向下拓展
   - **返回值**：
     - 所有候选节点的信息（索引、注意力分数、Value），供 final_compute 使用
     - 选中的 Top-K 节点的索引（仅非最底层），用于确定下一层候选集
   
   **边界情况处理**：
   - 当 query 位置 m 较小时，候选节点数量可能少于 512 或 8192。实现时需要动态处理：
     - 顶层候选节点数量可能 < 512（甚至可能只有几个节点）
     - 非顶层候选节点数量 = 上一层选中节点数 × 16（减去左边界 > m 的节点），可能远小于 8192
     - Top-K 选择时，K 应为 min(512, 实际候选节点数)
     - 所有数组和循环应使用实际的节点数量，而非硬编码的 512 或 8192

3. **final_compute**: 从参数传入每一层的候选节点和选中节点信息，执行最终注意力计算。实现流程：
   - **确定参与计算的节点**：
     - 最底层（层0）：该层的所有候选节点
     - 非最底层（层1到层L-1）：从候选节点中排除被选中用于向下拓展的 512 个节点
     - 注意：包含位置 m 的节点在每层都被选中，因此不会参与 final_compute（除了最底层）
   - **收集注意力分数和 Value**：
     - 从 compute_and_select 缓存的数据中提取参与计算节点的注意力分数和 Value
     - 这些分数是在不同层使用不同 RoPE 编码范围计算得到的，但可以直接使用
   - **计算最终输出**：
     - 对所有收集到的注意力分数执行 Softmax
     - 使用 Softmax 权重对 Value 进行加权求和
     - 返回最终的注意力输出

4. **forward_kernel**: 主 kernel，完整流程：
   - 调用 build_tree 构建树结构
   - 从顶层到底层，逐层调用 compute_and_select，收集候选节点和选中节点信息
   - 调用 final_compute 得到最终输出

它完成了上述完整的 Forward 过程。